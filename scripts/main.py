# -*- coding: utf-8 -*-
"""
Script for:
The environmental footprint of the Dutch healthcare sector: beyond environmental impact (in press)
Steenmeijer MA, Rodrigues JFD, Zijp MC, Waaijers-van der Loop SL
The Lancet Planetary Health

Tasks main.py:
    
    1. Prepare paths
    2. Load data from background EE-IOA objects and Statistics NL
    3. Prepare labels and classifications
    4. Perform EE-IOA calculation
    5. Adding direct impacts and other healthcare specific impacts
    6. Compile final results
    7. Process results for output files

@authors: Michelle A. Steenmeijer & Joao F. D. Rodrigues
"""
import pandas as pd
import numpy as np
import numpy.matlib
import os
import xlsxwriter
import sys
import matplotlib.pyplot as plt
from functions import *  # see 2C if this does not work

# These options determine the way floating point numbers, arrays and other NumPy objects are displayed.
np.set_printoptions(precision=2) 

##############################################
# 1) Prepare paths
##############################################

# 1A) Set base folder
# Folder settings: Change to reflect the location in your computer relative
# to the current working directory (run os.getcwd() to find out what that is)
# Set working directory to envr-footprint-healthcare folder
if str(os.getcwd()).endswith('scripts') == True:
    os.chdir(str(os.getcwd())[:-8])

if str(os.getcwd()).endswith('envr-footprint-healthcare') == False:
    print("Please set working directory to envr-footprint-healthcare folder")
    sys.exit()

mainpath = os.getcwd()

# 2B) Prepare folder structure
# Input data folder (not generated by scripts like the background data)
data_dir = mainpath + '\\data\\'

# Folder to write background files to (pickled prepared MRIO files) to
bg_dir = mainpath + '\\data\\bg\\'  
if not os.path.exists(bg_dir):
    os.makedirs(bg_dir)
mrio_dir = mainpath + '\\data\\bg\\pickled_mrio\\'  
if not os.path.exists(mrio_dir):
    os.makedirs(mrio_dir)

# Folder to export compressed file to
output_dir =  mainpath + '\\output'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# 2C) Find and import background.py
# if not found, add to the code before importing: 
#code_dir = mainpath + '\\scripts\\'
#os.chdir(code_dir)
## back to main file 
#os.chdir(mainpath)



##############################################
# 2) Retrieve data
##############################################


# 2A) Retrieve CBS data for 2016. If not needed to update, uncomment and only run next line
cbs_data = get_cbsdata(data_dir)  # Retrieve most up to date CBS data, can comment out after the first time
#cbs_data = pd.read_csv('cbs_data_2016.tsv', sep = '\t', index_col = [0, 1])  # Retrieve earlier compiled CBS data

cbs_data.iloc[1, 0] = 1  # assumed no conversion in calculation

# 2B) Create background object 
# That is, containing exiobase and stimulus
year = '2016'
#To rerun a second time faster comment the next
#line and uncomment the follow-up ones
bg = createBackground(mrio_dir, cbs_data, bg_dir, year)  
#bg_tmp = open(excel_dir + 'gddz_background_information.pkl',"rb")
#bg = pkl.load(bg_tmp)
#bg_tmp.close()



##############################################
#3)  Create labels, classification (incl for aggregation)
##############################################


# 3A) Labels name countries/regions
reg_labels = bg['label']['region'][['ISO3', 'Name', 'DESIRE region name']]
reg_labels.columns = ['ISO3','RegName', 'Region']

df_labels = {'sectxtcode' : list(bg['label']['industry'].reset_index()['CodeTxt']) * 49,
             'secname':list(bg['label']['industry']['Name']) * 49,
             'regiso3': np.repeat(list(bg['label']['region']["ISO3"]), 163),
             'regname':np.repeat(list(bg['label']['region']["Name"]), 163),
             'regregioncode': np.repeat(list(bg['label']['region']["DESIRE region"]), 163),
             'regregionname':np.repeat(list(bg['label']['region']["DESIRE region name"]), 163),
             }


# 3B) Labels impact categories > selection be changed in background file
char_labels = []
for k in range(len(bg['label']['characterization'])):
    chts = str(bg['label']['characterization']['Name'][k]) + ' (' + str(bg['label']['characterization']['Unit'][k]) + ')'
    char_labels.append(chts)
cols_impcat = [x for x in char_labels if x not in ['Value added (M.EUR)', 'Employment (1000 p.)']]


# 3C) Labels industry aggregation
excel_str = 'classifications.xlsx'
sheet_str = 'disagg_ind'  
sec_labels = pd.read_excel(data_dir + '\\exiobase_v3.7\\'  + excel_str, sheet_name = sheet_str, skiprows = 5)
sec_labels = sec_labels[['Code', 'Description', 'AggPos', 'AggDescription', 'AggCode', 'Scope', 'Scope_hotspot']]
sec_labels.rename(columns={'Code':'SecTxtCode', 'Description':'SecName', 'AggPos':'SAggPos', 'AggDescription':'SAggDescription', 'AggCode':'SAggCode'}, inplace = True)
fig_labels = pd.read_excel(data_dir + '\\exiobase_v3.7\\'  + excel_str, sheet_name = 'agg_ind_fig', skiprows = 5)


# 3D) Create multi-index for 163 sectors and 49 regions
multiindex = pd.MultiIndex.from_tuples(list(zip(list(df_labels['regiso3']), list(df_labels['sectxtcode']))))



##############################################
# 4)  EE-IOA footprint calculation
##############################################

# Arrays results
array_contrib = calc_contrib(bg['B'], bg['L'], bg['Ystim'])
array_hotspot = calc_hotspot(bg['B'], bg['L'], bg['Ystim'])

# Turn arrays to dataframes
df_contrib = df_fromarray(array_contrib, char_labels, multiindex, cols_impcat)
df_hotspot = df_fromarray(array_hotspot, char_labels, multiindex, cols_impcat)



##############################################
# 5) Adding direct impacts and other healthcare specific impacts
##############################################

cols_df = df_contrib[0].columns  # same for all

# Adding the direct healthcare emissions from bg['Hstim']
hc_dir_row = pd.Series(['NLD','B_HEAL', bg['Hstim'][:,0][0], bg['Hstim'][:,0][1], bg['Hstim'][:,0][2] ,bg['Hstim'][:,0][3], bg['Hstim'][:,0][6]], index = cols_df)

# Reading in an additional file filled with data concerning the additional impact sources
BU_data = pd.read_csv(data_dir + 'bottomup_data.txt', sep ='\t').set_index('Source')

# Adding the direct emissions from anaesthetic gases 
# (Venema et al., 2022)
anae_cc = BU_data.loc['Anaesthetic','Global warming (ktCO2eq)'].item()
anae_row = pd.Series(['NLD','B_ANAE', anae_cc, 0, 0, 0, 0], index = cols_df)

# Adding the direct emissions from pressurised metered dose inhaler 
# (Wichers & Pieters, 2022)
mdi_cc = BU_data.loc['pMDI','Global warming (ktCO2eq)'].item() 
mdi_row = pd.Series(['NLD', 'B_PMDI', mdi_cc, 0, 0 ,0 ,0], index = cols_df) 


# Adding the impact from individual travel
# The following are the final values calculated using ecoinvent (a licenced LCI), 
# based on the calculation described in the appendix. 

# Calculated impact from commuting
# ..for the contribution analysis
commute_c_row = pd.Series(['NLD', 'B_COMM'] +  list(BU_data.loc['Commute (total)']), index = cols_df)
# ..split in direct en indirect impacts for the hotspot analysis
commute_h_dir_row = pd.Series(['NLD', 'B_COMM'] + list(BU_data.loc['Commute (direct)']), index = cols_df)
commute_h_indir_row = pd.Series(['GLO', 'B_REST'] + list(BU_data.loc['Commute (indirect)']), index = cols_df)

# Calculated impact from travel by patients and visitors
visit_c_row = pd.Series(['NLD', 'B_VISI'] + list(BU_data.loc['Visitor travel (total)']), index = cols_df) 
# ..split in direct en indirect impacts for the hotspot analysis
visit_h_dir_row = pd.Series(['NLD', 'B_VISI'] + list(BU_data.loc['Visitor travel (direct)']), index = cols_df) 
visit_h_indir_row = pd.Series(['GLO', 'B_REST'] + list(BU_data.loc['Visitor travel (indirect)']), index = cols_df) 



##############################################
# 6) Compile total results
##############################################

# 6A) Append the additional rows to the input-output results
rows_c = [hc_dir_row, anae_row, mdi_row, commute_c_row, visit_c_row]
add_rows_c = pd.concat(rows_c, axis = 1, ignore_index=True).T

rows_h = [hc_dir_row, anae_row, mdi_row,
          commute_h_dir_row, commute_h_indir_row,
          visit_h_dir_row, visit_h_indir_row]
add_rows_h = pd.concat(rows_h, axis = 1, ignore_index=True).T

# append all additional rows to main dfs
df_contrib[0] = pd.concat([df_contrib[0], add_rows_c], ignore_index = True)
df_contrib[1] = pd.concat([df_contrib[1], add_rows_c], ignore_index = True)

df_hotspot[0] = pd.concat([df_hotspot[0], add_rows_h], ignore_index = True)
df_hotspot[1] = pd.concat([df_hotspot[1], add_rows_h], ignore_index = True)

# 6B)  Add region and sector aggregation & labels
# .. for the contribution analysis
df_c = []
for x in df_contrib:
    x = pd.merge(x, reg_labels, on = 'ISO3', how = 'left' )
    x = pd.merge(x, sec_labels[['SecTxtCode', 'SecName','SAggDescription', 'Scope']], on = 'SecTxtCode', how = 'left' )
    df_c.append(x)

# .. for the hotspot analysis
df_h = []
for x in df_hotspot:
    x = pd.merge(x, reg_labels, on = 'ISO3', how = 'left' )
    x = pd.merge(x, sec_labels[['SecTxtCode', 'SecName', 'SAggDescription', 'Scope_hotspot']], on = 'SecTxtCode', how = 'left' )
    x.rename(columns = {'Scope_hotspot': 'Scope'}, inplace = True)
    df_h.append(x)



##############################################
# 7) Output final results
##############################################
# Please note that this script read the most up-to-date data from Statistics 
# Netherlands (CBS), which can mean that the health care expenditure is 
# different to the results presented in the paper. 
# The conversion from basic price to purchaser price was done using rounded values,
# causing the results from this model to vary slightly (<1%), with insignificant
# implication to the results.

os.chdir(output_dir)

# 7A) Expenditure vector
# column 'Total (MEUR)' is the sum of the expenditure on Healthcare services,
# Pharmaceuticals & consumables and Medical durable goods
cols_Y = ['Total (MEUR)','Healthcare services','Pharmaceuticals and consumables','Medical durables goods']
Y_df = pd.DataFrame(bg['Ystim'], columns = cols_Y, index = multiindex)
Y_df = Y_df.reset_index()
Y_df.columns = ['ISO3', 'SecTxtCode'] + cols_Y
Y_df = pd.merge(Y_df, reg_labels, on = 'ISO3', how = 'left' )
Y_df = pd.merge(Y_df, sec_labels[['SecTxtCode', 'SecName', 'SAggDescription']], on = 'SecTxtCode', how = 'left' )
Y_df = Y_df[['ISO3', 'RegName', 'Region', 'SecTxtCode', 'SecName',
       'SAggDescription'] + cols_Y]

Y_allsec = Y_df.groupby(['SecTxtCode', 'SecName'])[cols_Y].sum()
Y_aggsec_aggreg = Y_df.groupby(['RegName', 'SAggDescription'])[cols_Y].sum()
Y_aggsec = Y_df.groupby(['SAggDescription'])[cols_Y].sum()

# Read expenditure vector to xlsx for several aggregation levels
writer = pd.ExcelWriter('ExpenditureVector.xlsx', engine='xlsxwriter')
Y_df.to_excel(writer, sheet_name='full')
Y_allsec.to_excel(writer, sheet_name='allsec')
Y_aggsec_aggreg.to_excel(writer, sheet_name='aggsec_aggreg')
Y_aggsec.to_excel(writer, sheet_name='aggsec')
writer.save()


# 7B) Multipliers / Coefficients / Intensities
# join the impact results with the expenditure vector
mult_all = pd.concat([Y_df.iloc[:,:-3], df_contrib[0].iloc[:163 * 49, 2:]], axis = 1)
mult_all = mult_all[mult_all['Total (MEUR)'] != 0]  # cannot divide by zero
for x in cols_impcat:
    mult_all[x] = mult_all[x].astype('float')

# Aggregate to later get the weighted average per (aggregated) product group
mult_aggsec_aggreg = mult_all.groupby(['RegName', 'SAggDescription'])[['Total (MEUR)', 'Global warming (ktCO2eq)', 'Material extraction (kt)', 'Blue water consumption (Mm3)','Land use (km2)', 'Waste generation (kt)']].sum()
mult_aggsec = mult_all.groupby(['SAggDescription'])[cols_impcat + ['Total (MEUR)']].sum()
mult_allsec = mult_all.groupby(['SecName'])[cols_impcat + ['Total (MEUR)']].sum()

for df in [mult_all, mult_aggsec_aggreg, mult_aggsec, mult_allsec]:
    for x in cols_impcat:
        df[str(x)+'/MEUR'] = df[x] / df['Total (MEUR)']
        del df[x]


# Write coefficients/multipliers/intensities to xlsx for several aggregation levels
writer = pd.ExcelWriter('Intensities.xlsx', engine='xlsxwriter')
mult_all.to_excel(writer, sheet_name='full')
mult_allsec.to_excel(writer, sheet_name='allsec')
mult_aggsec_aggreg.to_excel(writer, sheet_name='aggsec_aggreg')
mult_aggsec.to_excel(writer, sheet_name='aggsec')
writer.save()


# 7C) Dataframe for Table 1 
s1 = df_contrib[0].iloc[:,2:].sum()
s2 = df_contrib[1].iloc[:(163 * 49) + 1, 2:].sum()  # total plus direct impacts
s3 = df_contrib[2].iloc[:,2:].sum()
s4 = df_contrib[3].iloc[:,2:].sum()
s_anae = df_contrib[0].iloc[(163 * 49) + 1, -5:]
s_pmdi = df_contrib[0].iloc[(163 * 49) + 2, -5:]
s_travel = df_contrib[0].iloc[(163 * 49) + 3, -5:] + df_contrib[0].iloc[(163 * 49) + 4, -5:]

t1 = pd.concat([s1, s2, s3, s4, s_anae, s_pmdi, s_travel], axis = 1)
t1.columns = ['Total', 'Healthcare services', 'Pharmaceuticals and chemical products',
               'Medical appliances', 'Release of anaesthetic gases', 
               'Release of pMDI propellants', 'Private travel']
t1 = t1.T

bp_HCserv = cbs_data.iloc[0, 0].item()
bp_phar = cbs_data.iloc[0, 1].item() * cbs_data.iloc[1, 1].item()
bp_appl = cbs_data.iloc[0, 2].item() * cbs_data.iloc[1, 2].item()

t1['Expenditure (MEUR)'] = [(bp_HCserv + bp_phar + bp_appl), bp_HCserv, bp_phar, bp_appl, 'NA', 'NA', 'NA']

# Read Table 1 to Excel file
t1.to_excel('Table1.xlsx')


# 7D)  Results Table S5
R_HC = df_contrib[0].iloc[:,2:].sum()  # Healthcare footprint totals

# Final consumption footprint
k_NL = 20  # Netherlands position among 49 countries
Y_nl = bg['Y'][:, k_NL * 7: (k_NL + 1)* 7].sum(1)  # Total final demand NL
BxL_NL = np.dot(bg['B'], bg['L'])  # Calculate multipliers/intensities/coefficients
R_ind = np.dot(BxL_NL, Y_nl)  # Indirect impacts from NL total final demand 

R_y = bg['H'][:, k_NL * 7: (k_NL + 1)* 7].sum(1)  # Direct impacts from NL total final demand 

R_ind = np.delete(R_ind, [4, 5])  # Remove value added and nr of employees 
R_y = np.delete(R_y, [4, 5])

share_hc = pd.concat([R_HC, pd.Series(data = np.add(R_y, R_ind), index = cols_impcat)], axis = 1)
share_hc.columns = ['Healthcare footprint', 'National consumption footprint']
share_hc['Healthcare share of national consumption footprint (%)'] = 100* share_hc['Healthcare footprint'] / share_hc['National consumption footprint']

# Read Table S5 to Excel file
share_hc.to_excel('TableS5.xlsx')


# 7E) Contribution analysis (underlying data for Figure 1 and Table S6)
df_c_all = df_c[0][['ISO3','RegName', 'Region', 'SecTxtCode', 'SecName', 'SAggDescription', 'Scope'] + cols_impcat]
df_c_aggsec = df_c[0].groupby(['SAggDescription'])[cols_impcat].sum()
df_c_allsec = df_c[0].groupby(['SecTxtCode', 'SecName'])[cols_impcat].sum()

# coefficients/multipliers/intensities to csv for several aggregation levels
writer = pd.ExcelWriter('ContributionAnalysis.xlsx', engine='xlsxwriter')
df_c_all.to_excel(writer, sheet_name='full')
df_c_allsec.to_excel(writer, sheet_name='allsec')
df_c_aggsec.to_excel(writer, sheet_name='aggsec')
writer.save()

# Hotspot analysis (underlying data for Figure 2, 3 and Table S7, S8)
df_h_all = df_h[0][['ISO3','RegName', 'Region', 'SecTxtCode', 'SecName', 'SAggDescription', 'Scope'] + cols_impcat]
df_h_all.loc[df_h_all['ISO3']=='GLO', ['RegName', 'Region']] = 'Global'

df_h_aggsec = df_h_all.groupby(['Scope','SAggDescription'])[cols_impcat].sum()
df_h_aggsec_aggreg = df_h_all.groupby(['Scope', 'RegName','SAggDescription'])[cols_impcat].sum()
df_h_aggreg = df_h_all.groupby(['Scope', 'Region', 'RegName'])[cols_impcat].sum()
df_h_allreg = df_h_all.groupby(['Scope', 'RegName'])[cols_impcat].sum()
df_h_allsec = df_h_all.groupby(['Scope', 'SecTxtCode', 'SecName'])[cols_impcat].sum()

writer = pd.ExcelWriter('HotspotAnalysis.xlsx', engine='xlsxwriter')
df_h_all.to_excel(writer, sheet_name='full')
df_h_aggsec.to_excel(writer, sheet_name='aggsec')
df_h_aggsec_aggreg.to_excel(writer, sheet_name='aggsec_aggreg')
df_h_aggreg.to_excel(writer, sheet_name='aggreg')
df_h_allreg.to_excel(writer, sheet_name='allreg')
df_h_allsec.to_excel(writer, sheet_name='allsec')
writer.save()


# 7F) plot figures (figures in manuscript are composed in MS Excel)
# Figure 1
fig_1 = pd.merge(df_c_aggsec.reset_index(), sec_labels[['SAggDescription','SAggCode']].drop_duplicates(), on = 'SAggDescription', how = 'left')
fig_1 = pd.merge(fig_1, fig_labels, on = 'SAggCode', how = 'left') 
fig_1 = fig_1.groupby('Contribution')[cols_impcat].sum()

# Figure 2
fig_2 = pd.merge(df_h_aggsec.reset_index(), sec_labels[['SAggDescription','SAggCode']].drop_duplicates(), on = 'SAggDescription', how = 'left')
fig_2 = pd.merge(fig_2, fig_labels, on = 'SAggCode', how = 'left') 
fig_2 = fig_2.groupby('Hotspot')[cols_impcat].sum()

# Figure 3
fig_3 = df_h_all.groupby(['Region'])[cols_impcat].sum()

# Plot and save figures
n = 1
for df in [fig_1, fig_2, fig_3]:
    for col in df.columns:
        df[col] = 100 * df[col]/df[col].sum()
    df.T.plot(kind='bar', stacked=True, colormap='tab10', figsize=(10, 6))
    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')#  ncol=1)
    plt.xlabel("Impact category")
    plt.ylabel("Share of footprint")
    plt.show()
    plt.savefig('fig_' + str(n)  + '.png')
    print('fig_' + str(n)  + '.png')
    n = n + 1